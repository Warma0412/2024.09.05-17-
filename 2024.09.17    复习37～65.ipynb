{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fe4ab23-b180-4564-886c-9ae8bcfd9ae3",
   "metadata": {},
   "source": [
    "#### 2024.9.17\n",
    "\n",
    "**今日学习：\n",
    "复习37～65**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd181b9c-561b-439f-8abb-103b1bfe6395",
   "metadata": {},
   "source": [
    "#### 一、Markdown\n",
    "\n",
    "**（1）基础注释语法:**\n",
    "\n",
    "        1.多选命令行：\n",
    "                    shift多选命令行\n",
    "        2.插入公式样式：\n",
    "                    使用$公式$\n",
    "                    独占一行的公式，则使用$$公式$$，如# $$x^2 + y^2 = 1$$\n",
    "        3.复杂的公式：\n",
    "                    使用LaTex语法\n",
    "        4.快捷键：\n",
    "                    shift&enter：运行当前单元格，并跳转到下一个单元格\n",
    "        5.标题级别#\n",
    "                    # 这是一级标题\n",
    "                    ## 这是二级标题\n",
    "        6.加粗**\n",
    "                    **加粗内容**\n",
    "        7.斜体*\n",
    "                    *斜体内容*\n",
    "        8.加粗&斜体***\n",
    "                    ***加粗&斜体内容***\n",
    "        9.删除~~\n",
    "                    ~~横线删除内容~~\n",
    "                    注意：波浪号是英文输入法中的小波浪\n",
    "        10.换行：\n",
    "                    在两行内容之间加上一个空白行\n",
    "        11.列表：\n",
    "                    （1）无序列表：在列表原色前加上\"- \"\n",
    "                    （2）有序列表：在列表原色前加上\"1. \"\n",
    "        12.插入链接：\n",
    "                    [b站链接](https://www.bilibili.com)\n",
    "        13.插入图片：\n",
    "                    [图片说明]方括号中的文字是当图片加载失败时，便会显示那个文字作为替代\n",
    "        14.插入引用：\n",
    "                    > 引用内容\n",
    "        15.插入代码：\n",
    "                    `代码`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaf8f46-4fca-4267-877a-a3a83ed53743",
   "metadata": {},
   "source": [
    "#### 二、LaTex\n",
    "\n",
    "**（1）基础公式语法:**\n",
    "\n",
    "        1.插入公式：\n",
    "                    $公式$\n",
    "                    换行公式$$公式$$\n",
    "        2.介绍LaTeX：\n",
    "                    LaTeX并不是一个专门用来写数学公式的语言，而是一个排版系统\n",
    "        3.加减乘除：\n",
    "                    加+\n",
    "                    减-\n",
    "                    乘\\times\n",
    "                    除\\div\n",
    "        4.上下标：\n",
    "                    上标^\n",
    "                    下标H_2O\n",
    "                    LaTeX默认上标和下标仅包含一位字符，因此添加多位字符时可使用{}进行组合----UP_{warma}\n",
    "        5.求和求根：\n",
    "                    求和\\sum----\\sum(x^2+y^2)\n",
    "                    求根\\sqrt[n]----\\sqrt[3]x\n",
    "        6.分数线：\n",
    "                    \\frac{分子}{分母}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1d7e9be-38af-46ed-8977-a2adb2f75afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830935fe-92b6-43ec-9011-58812578f153",
   "metadata": {},
   "source": [
    "#### 三、NumPy\n",
    "\n",
    "**（1）基础介绍:**\n",
    "\n",
    "        1.介绍：\n",
    "                    全称numerical python，专门针对计算使用，是很多数据或科学相关python包的基础，包括pandas\n",
    "                    其中最核心的数据结构叫 ND array ，意思是n维数组\n",
    "                    如一维数组：[1, 2, 3, 4, 5]；\n",
    "        2.创建数组：\n",
    "                    （1）创建一维数组\n",
    "                                array_1 = np.array([1, 2, 3])\n",
    "                    （2）创建二维数组\n",
    "                                array_2 = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "                    （3）如果传入的元素数据类型不一致，numpy便会强制将其转换为同一类型\n",
    "                                array_3 = np.array([1, \"warma\", True])\n",
    "        3.数组属性：\n",
    "                    （1）print(array_1.ndim)\n",
    "                                .ndim会返回给我们数组的维度\n",
    "                    （2）print(array_1.shape)\n",
    "                                .shape会返回一个元组，表示各个维度的元素个数\n",
    "                    （3）print(array_1.size)\n",
    "                                .size会返回给我们数组里元素的总个数\n",
    "                    （4）print(array_1.dtype)\n",
    "                                .dtype会返回给我们数组元素的类型，如int64，其中int表示整数类型，64表示64位比特长度\n",
    "        4.批量创建数组：\n",
    "                    （1）np.zeros(3)\n",
    "                                创建3个元素为0的数组；其中返回的数字都是浮点数\n",
    "                    （2）np.ones(5)\n",
    "                                创建5个元素为1的数组\n",
    "                    （3）np.arange(0, 6, 2)\n",
    "                                类似python中的range()方法，从0开始，到5，步长为2，即针对array的range()方法\n",
    "        5.拼接一维数组：\n",
    "                    使用np.concatenate([ ])将多个列表中的元素拼接起来\n",
    "                                np.concatenate([array_1, array_2])\n",
    "        6.数组排序：\n",
    "                    np.sort()就类似与sorted，不改变原始排序，借用此生成一个新的排序\n",
    "                                array_4sort = np.sort(array_4)\n",
    "        7.索引获得元素：\n",
    "                    array_1[0]\n",
    "                    array_1[0:2]\n",
    "        8.数组运算：\n",
    "                    如形状相同的两个一维数组相加，便会返回一个相同位置元素相加后的数组\n",
    "                    加+、减-、乘*、除/\n",
    "                    array_1 + array_2\n",
    "        9.聚合运算方法：\n",
    "                    之所以叫聚合操作，是因为它们都是通过一组值来得到一个值\n",
    "                    array_1.max()\n",
    "                    array_1.min()\n",
    "                    array_1.mean()\n",
    "                    array_1.sum()\n",
    "        10.根据条件筛选数组元素：\n",
    "                    属于数组和数字之间的操作，同时也可以结合逻辑符号且或非 & | ~\n",
    "                    array_1[array_1 > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14c08694-91d8-4355-a6fa-497423dcaf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16af5db8-c3f4-4fa9-ba08-0a143fd5fc5a",
   "metadata": {},
   "source": [
    "#### 四、Pandas\n",
    "\n",
    "**（1）Series:**\n",
    "\n",
    "        1.介绍：\n",
    "                    pandas继承numpy，但性能更好\n",
    "        2.Series数据结构：\n",
    "                    Series是pandas的一个数据结构，类似于numpy的一个数组\n",
    "                    s1 = pd.Series([1, 3, 5, 7, 9])\n",
    "        3.Series的索引：\n",
    "                    不同于numpy数组的index固定从0开始，Series的索引可以自定义，如从a开始···自定义的索引称为标签索引\n",
    "                    s3 = pd.Series([1, 2, 3], index=[\"a\", \"b\", \"c\", ])\n",
    "        4.更好的索引方法：\n",
    "                    loc：表示用标签索引去取值or切片\n",
    "                    iloc：表示用位置索引去取值or切片\n",
    "        5.创建Series的另一种方式：\n",
    "                    给Series这个构造函数直接传入一个字典，字典的键key会自动变成对应的标签索引\n",
    "        6.筛选Series元素：\n",
    "                    类似于numpy\n",
    "                    s4 > 19 返回bool数组\n",
    "        7.索引对齐-计算:\n",
    "                    Series中的计算会自动根据索引对齐，只有当某个索引同时出现在两个Series里时，才会返回结果，否则会返回NaN\n",
    "                            s3 = pd.Series([1, 2, 3, 4, 5, 6, 7],index = [7, 6, 5, 4, 3, 2, 1])\n",
    "                            s4 = pd.Series([-1, -2, -3, -4, -5, -6],index = [5, 4, 3, 2, 1, 0])\n",
    "                            s3 + s4\n",
    "                                    如果某个索引只存在于其中一个Series，则会返回 NaN，表示not a number，说明无法得到计算值\n",
    "                            s3.add(s4, fill_value = 0) \n",
    "                                    此处用.add()可以传入fill_value = 0，即将两边 Series单独索引设定默认值\n",
    "                                    同理还有以下方法\n",
    "                                            sub()减法\n",
    "                                            mul()乘法\n",
    "                                            div()除法\n",
    "                                    四个统计方法仍与 array一样使用\n",
    "                                            s3.max()\n",
    "                                            s3.min()\n",
    "                                            s3.mean()\n",
    "                                            s3.sum()                    \n",
    "        8.describe方法：\n",
    "                    Series中的.describe()是array中没有的，可以返回很多关于这个Series的统计信息\n",
    "                    s3.describe()\n",
    "        9.对元素分别操作：\n",
    "                    同NumPy数组array中，也可以使用s1 * 3对Series中的每个元素进行操作\n",
    "                            但如果我们希望每个成绩数据对应的等级，可以使用def ···\n",
    "                            以及通过使用apply方法，将函数作用于Series中的每一个元\n",
    "\n",
    "**（2）DataFrame:**\n",
    "\n",
    "        1.DataFrame构成：\n",
    "                    如用户的id是一个Series，用户的年龄是一个Series\n",
    "                    那么由多个Series组成的数据结构，我们称之为DataFrame\n",
    "        2.创建DataFrame方法：\n",
    "                    将pd.DataFrame()的参数传入一个字典，key为各个Series对应的键名，value是各个Series变量\n",
    "                            s_id = pd.Series(···)\n",
    "                            s_class = ···\n",
    "                            s_grade = ···\n",
    "                            df_1 = pd.DataFrame({\"学号\":s_id, \"班级\":s_class, \"成绩\":s_grade})\n",
    "                                    如果我们传入的Series有标签索索引的话，则DataFrame的索引也会变成对应的标签\n",
    "        3.获得DataFrame的索引和列名：\n",
    "                    .index获取 索引\n",
    "                    .columns获取 列名\n",
    "                    .values获取 值\n",
    "                            df_2.index\n",
    "        4.对Dataframe进行T转置：\n",
    "                    .T 会将返回的结果的行与列进行转置\n",
    "                            df_2.T\n",
    "        5.提取列数据：\n",
    "                    df[\"列名\"] 即可提取对应key的值\n",
    "                            借此提取的是列，但列也是一个Series，也会将原本DataFrame对应的索引提取出来\n",
    "                    df_2[\"班级\"]\n",
    "                    df_2.班级\n",
    "                            使用.列名 一样，因为每列 Series实际上也是 DataFrame的属性\n",
    "                            提取多列可使用df[[\"列1\", \"列2\"]]\n",
    "        6.提取行数据：\n",
    "                    df.loc[\"索引名\"]\n",
    "                    df.iloc[\"索引名\"]\n",
    "                            df_2.loc[\"沃玛\"]\n",
    "                                    巧记：i一般是数字，带i的就是用数字表示的位置\n",
    "        \n",
    "        7.提取某个值：\n",
    "                    df.loc[\"索引\", \"列名\"]\n",
    "                    df.iloc[索引位置, 列名位置]\n",
    "                            df_2.loc[\"沃玛\", \"成绩\"]\n",
    "        \n",
    "        8.条件筛选：\n",
    "                    DataFrame中一行是一个实例，一列是一个属性（和Series条件筛选基本一样）\n",
    "                            df_2[(df_2[\"成绩\"] > 80) & (df_2[\"班级\"] == \"二班\")]\n",
    "        9.更新DataFrame中的列：\n",
    "                    如果我们想把其中一列的值进行替换，可以通过重新赋值来达成，即 df[\"\"] = s_新\n",
    "                            df_1[\"成绩\"] = s_grade_new\n",
    "                                    df_1[\"成绩\"] = [100, 70, 70, 60]\n",
    "                                    替换数据使用python列表也是可以的，根据顺序对齐\n",
    "                            df_1[\"班级\"] = [\"一班\", \"二班\", \"二班\", \"一班\"]\n",
    "                                    赋值时若列名不存在，则会根据列名与值创建一个新的列                   \n",
    "        10.更新DataFrame中的行：\n",
    "                    更新行也是一样的道理：我们既然可以通过df.loc[]提取一行数据，则通过连接 = 同样可以更新一行的数据\n",
    "                    即 df.loc[\"索引\"] = pd.Series([values], index=[])        \n",
    "        11.删除DataFrame中的行or列：\n",
    "                    删除行：df.drop([\"002\", \"004\"])\n",
    "                    删除列：df.drop([\"身高\", \"性别\"], axis=1)\n",
    "                            .drop()方法会自动返回删除后的结果，但不会修改原DataFrame，真删则赋值df_2 = df.drop()\n",
    "                                    df_2 = df_1.drop([\"身高\", \"班级\"], axis=1)\n",
    "                                    对列进行drop操作一定要设置 axis =1（对于行，即实例的删减，默认axis=0）                   \n",
    "        12.DataFrame与DataFrame之间的操作：\n",
    "                    此时索引和索引、列名和列名也会自动对齐\n",
    "                            df_3 + df_4\n",
    "                            df_3.add(df_4, fill_value=0)\n",
    "                                    当某个元素值在两个DataFrame中都不存在，即压根没有进行相加操作，因此也不存在替换，还是NaN\n",
    "                                    同理.sub()、.mul()、.div()减、乘、除\n",
    "        13.DataFrame与Series之间的操作：\n",
    "                    df_3 * s_mul\n",
    "                            s_mul中索引a的值，会与df_3中a列下面的每一个值进行相乘\n",
    "                            s_mul中索引d的值是NaN，相乘后使得原本有数据的d列也变成了NaN\n",
    "                            s_mul有索引e的值，但df_3中没有e列的值，也是NaN，即相乘后的结果也是NaN\n",
    "                                    df_1 * 5\n",
    "                                    DataFrame与单个数字进行操作，即使是字符串也会被进行对应操作----即重复字符串5次\n",
    "        14.常用方法：\n",
    "                    axis=0即纵向操作----drop时axis=0，即将索引行上的数据一个个删除，处理纵轴上的数据；但在统计上直接处理纵轴数据\n",
    "                    axis=1即横向操作----drop时axis=1，即将列名上的数据一个个删除，处理横轴上的数据；但在统计上直接处理横轴数据\n",
    "                            df_1.mean()\n",
    "                                    默认axis=0，对纵轴数据求平均，即a行的平均值为1.5\n",
    "                            df_1.mean(axis=1)\n",
    "                                    设定axis=1，对横轴数据求平均，即\"001\"的平均值为2.75\n",
    "        15.applymap：\n",
    "                    除apply接收方法以外，还有applymap接收函数；\n",
    "                            区别：传给apply的函数，会被运用在每一行or每一列上\n",
    "                                 传给applymap的函数，会被运用在每一个元素上\n",
    "                            注意：无论apply还是applymap都不会改变原始DataFrame，只会返回处理后的结果，如果需要保存该案后的结果，仍需额外赋值=        \n",
    "        16.describe：\n",
    "                    类似Series中的describe()，一样得到统计数据----且会自动忽略非数字类型的数据\n",
    "        17.astype(\" \")：\n",
    "                    当使用describe时，如果DataFrame中的数据类型不是int而是object，则即使数字看起来是int，但describe时也会出现错误\n",
    "                    此时就要使用df[\"列名\"] = df[\"列名\"].astype(\"int\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc7717a-2973-44bf-a657-c34a249ad8a5",
   "metadata": {},
   "source": [
    "#### 五、处理数据\n",
    "\n",
    "**（1）获取数据:**\n",
    "\n",
    "        1.数据分析流程\n",
    "                    数据获取-读取数据-评估数据-清洗数据-整理数据-分析数据-可视化数据    \n",
    "        2.数据分类\n",
    "                    私密数据：如公司内部数据\n",
    "                    公开数据：通过直接下载、爬虫、公开API获取等\n",
    "                            API定义了两个程序之间的服务合约，包括 发送相应的客户端&发送请求的客户端（双方如何通过请求与响应进行通讯的）\n",
    "                                    使用爬虫时，发送请求后，获得的是网页源代码，其本身是用来给浏览器渲染的；\n",
    "                                    我们为了从中寻找数据，需要自己再去解析网页源码\n",
    "        3.文件后缀介绍：\n",
    "                    文件后缀名会影响系统使用什么软件打开它，但不影响其内容\n",
    "        4.JSON数据格式：\n",
    "                    （1）JSON对象：python字典{}\n",
    "                    （2）JSON数组：python列表[]\n",
    "                             规则：\n",
    "                                （1）JSON数据中只能是字符串作为key，且该字符串必须被双引号\"\"包围，''不行\n",
    "                                （2）JSON中的值必须是 字符串、数字、布尔值true、数组[]、对象{}、空值null 中的一种\n",
    "                                            布尔值遵循java规则，为小写字母开头\n",
    "                                （3）JSON数据类型可以是第二点中的六种数据的任意搭配\n",
    "        5.CSV数据格式：\n",
    "                    一般文件第一行是表格头，即展示列名的那一行（也可以没有标题头）\n",
    "                    表格头下面，每一行数据独占一行\n",
    "                    每一行的逗号分隔符的数量一致，否则就不是合格的CSV文件了\n",
    "\n",
    "**（2）读取数据:**\n",
    "\n",
    "        1.读取数据-JSON：\n",
    "                    pd.read_json函数\n",
    "                            导入pandas后，使用pd.read_json(\"文件路径.json\")进行读取，会自动完成文件读取、JSON解析、转化为DataFrame全流程\n",
    "                            虽然JSON是程序员最喜欢的数据格式，却并不是数据分析师最喜欢的数据格式\n",
    "        2.读取数据-CSV：\n",
    "                    pd.read_csv函数\n",
    "                            CSV格式的优点：体积小、结构工整、易理解、可直接用excel打开\n",
    "                            pd.read_csv(\"文件路径\")\n",
    "                                    如果第一行直接就是数据，则添加 header=None\n",
    "                                    如果想将数据中的其中一列设定为标签索引时，则添加index_col=\"列名\"\n",
    "                                    pd.set_option(\"display.max_columns\", 150) 将展示列数上限调整为150（默认为20列）\n",
    "                                    pd.set_option(\"display.max_colwidth\", 500)将内容展示字符上限调整为500（默认为50字符）\n",
    "                    获取开头n行-head()\n",
    "                    获取结尾的几行数据，可使用df.tail()方法\n",
    "                    了解数据基本信息-info()\n",
    "                    了解数据统计信息-describe()\n",
    "\n",
    "**（3）评估数据:**\n",
    "\n",
    "        1.评估数据介绍:\n",
    "                    （1）结构：根据结构清晰程度分为 乱数据——整洁数据\n",
    "                    （2）内容：根据内容是否需要清理分为 脏数据——干净数据\n",
    "                                     如存在数据丢失、重复数据、不一致数据（如1班与一班）、无效或错误数据\n",
    "        2.快速了解数据概况：\n",
    "                    df.info()可以快速查看DataFrame数据的概况\n",
    "                    df.sample(n)可以获取随机n行数据\n",
    "                            如果数据中列数过多or值太长时，可以通过pd.set_option(\"display.max_columns&colwidth\", n)调整\n",
    "        3.如何发现空缺值：\n",
    "                    通过df.info()查看Non-Null Count数据数量，就能看出是否有缺失值\n",
    "                    也可以通过调用.isnull()方法检查值是否为空缺值，在Series和DataFrame都能使用----返回True即为空缺值\n",
    "                            df_fifa.isnull()\n",
    "                            df_fifa.isnull().sum()\n",
    "                                    可以得到各列中空缺值的数量\n",
    "                                    True在计算里被视为1，False视为0\n",
    "        4.提取存在空缺值的行：\n",
    "                    调用Series[Series[\"列名\"].isnull()]可以提取出Series中指定列存在空缺值的行\n",
    "                            因为Series[\"列名\"].isnull()会返回关于制定列的bool列表，仅提取其中值为True的行\n",
    "                                    DataFrame也同理\n",
    "        5.评估重复值：\n",
    "                    Series和DataFrame都可以调用.duplicated()方法来检查值或行是否重复\n",
    "                            df_fifa[\"sofifa_id\"].duplicated()\n",
    "                                    当\"sofifa_id\"行不存在重复值时返回False\n",
    "                            df_fifa.duplicated(subset=[\"sofifa_id\", \"player_url\"])\n",
    "                                    subset=[\"列1\", \"列2\"]，即只有列1与列2完全重复时，才会返回 True\n",
    "        6.评估不一致数据：\n",
    "                    借用Series[\"列名\"].value_counts()方法，会返回Series指定列中各个值的个数\n",
    "                    其他：.sort_values()、.describe()\n",
    "\n",
    "**（4）清洗数据:**\n",
    "\n",
    "        1.手动清洗·索引&列名\n",
    "                    如果在读取数据后发现数据的索引or列名存在混乱时，可以使用rename()方法\n",
    "                            重命名索引：df.rename(index={···})\n",
    "                            重命名列名：df.rename(columns={···})\n",
    "                                    df_1.rename(index={\"002\":\"02\",\"0004\":\"04\"}) \n",
    "                                            花括号{}中分别放入 需要修改&修改后的值\n",
    "        2.自动清洗·索引&列名：\n",
    "                    如果需要清洗的索引&列名很多，手动一个个输入清洗很麻烦，可以将字典{}换成 函数or方法\n",
    "                            df_1.rename(columns=str.upper)\n",
    "                            调用后将列名进行大写\n",
    "        3.将某列设为索引：\n",
    "                    使用.set_index()方法\n",
    "                    修改索引为列名后，如果想修改回默认索引，则可以使用.reset_index()方法\n",
    "        4.将索引&列名重新排序：\n",
    "                    调用df.sort_index()可以对索引or列名进行排序\n",
    "                    默认axis=0，是沿着索引纵向操作，即对索引进行排序\n",
    "        5.转置数据结构：\n",
    "                    df.T\n",
    "        6.拆分列（多个属性构成一列）：\n",
    "                    str.split(\"拆分值\")\n",
    "                            如果想要根据分隔符将一列数据拆分为两列，需要传入参数 expand=True ，表示将拆分后的值表示为两个Series\n",
    "        7.将不同列组合成一列：\n",
    "                    str.cat()\n",
    "        8.将宽数据转换为长数据：\n",
    "                    实质是将一部分列名的值转换为变量的值\n",
    "                    可以调用pd.melt()方法\n",
    "        9.对行进行拆分\n",
    "                    如某列的值为是一个列表，而不是独立的值，可以调用.explode(\"列名\")方法将该列中的元素转换为单独一行的DataFrame\n",
    "        10.对行or列进行删除\n",
    "                    使用.drop()方法\n",
    "                            传入[ ]删除多个行or列，如df_4.drop([\"02\",\"04\"])\n",
    "                            axis=1删除列，默认删除索引\n",
    "\n",
    "        11.注意：\n",
    "                    上述十条是根据数据的结构进行划分的 乱数据&整洁数据 ----对应常用操作\n",
    "                    下列命令是根据数据的内容进行划分的 脏数据&干净数据 ----对应常用操作\n",
    "\n",
    "        11.对整列缺失值进行填充：\n",
    "                    若想填入一个统一值，则可针对列的赋值操作直接搞定\n",
    "                    df_1[\"国家\"] = \"中国\"\n",
    "        12.对某个缺失值进行填充：\n",
    "                    使用loc或iloc先去定位到那个值----loc()根据标签位置\n",
    "                    df_1.loc[\"02\", \"成绩\"] = 95\n",
    "        13.对部分缺失值进行填充：\n",
    "                    也是使用loc或iloc提取那一部分\n",
    "                    df.loc[\"起点行 \":\"终点行 \", \"列名 \"]\n",
    "        14.自动找到缺失值进行填充：\n",
    "                    调用.fillna()方法自动找到全部的NaN的值并进行填充----填充缺失值是None\n",
    "                    df_2[\"国家\"].fillna(\"空缺国家\")\n",
    "        15.删除有缺失值的行：\n",
    "                    调用.dropna()即删除存在缺失值的行\n",
    "                            默认是axis=0，即删除有缺失值的行；删除列时即调用axis=1\n",
    "                    df_2.dropna(subset=[\"国家\"])\n",
    "        16.删除重复数据：\n",
    "                    调用.drop_duplicates()删除重复数据\n",
    "                            对于Series即删除重复值；\n",
    "                            对于DataFrame即删除全部值相同的行\n",
    "        17.对值进行替换：\n",
    "                    调用.repalce(\"老值\"，\"新值\")，将表达同一意思的\"1班\"替换为\"一班\"\n",
    "        18.对值的类型进行转换：\n",
    "                    因为例如求平均只能不能用于字符串数据类型等\n",
    "                    调用.astype(数据类型)\n",
    "                            数据可分为两种类型：\n",
    "                                    1.分类数据：包含有限数量的不同类别的数据----如男女的性别，是有限的\n",
    "                                    2.数值数据：具体测量的数据，无限的----如0-1之间就有无限个数据\n",
    "        \n",
    "        19.保存清洗后数据：\n",
    "                    通过调用pd.read_scv()方法来读取scv文件\n",
    "                    之后便可以通过调用 df.to_csv(\"文件路径\") 写入csv文件\n",
    "                            读取刚刚保存的csv文件，但发现第一列怪怪的\n",
    "                                    因为无法识别第一列为索引，便将其作为第一列的数据\n",
    "                                    且该列无列名，便自动添加列名 \"Unnamed: 0 \"\n",
    "                            通过调用 index=False 便可不保存索引"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
